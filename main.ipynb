{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines Detection Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrating the Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals used internally by the calibrateCamera function\n",
    "gCamCalMatrix = None\n",
    "gCamCalDistortionCoeff = None \n",
    "\n",
    "def calibrateCamera():\n",
    "    # return if the global camCalMatrix already exists\n",
    "    global gCamCalMatrix\n",
    "    global gCamCalDistortionCoeff\n",
    "    \n",
    "    if(gCamCalMatrix is not None):\n",
    "        return gCamCalMatrix, gCamCalDistortionCoeff\n",
    "    \n",
    "    return gCamCalMatrix, gCamCalDistortionCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Image Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortionCorrection(img, matrix, coeff):\n",
    "    correctedImage = img\n",
    "    \n",
    "    return correctedImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accentuating Lane Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorTransform(img):\n",
    "    # TODO: pass in type\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobelGradientBinary(img):\n",
    "    # TODO: pass in parameters for threshes\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiteAndYellowBinary(img):\n",
    "    # TODO: highlight the white and yellow parts of image\n",
    "    # TODO: pass in type\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accentuateLaneLines(img):\n",
    "    # TODO: put this function in a different file\n",
    "    colorTransformImage = colorTransform(img)\n",
    "    sobelGradientBinaryImage = sobelGradientBinary(img)\n",
    "    whiteAndYellowBinaryImage = whiteAndYellowBinary(colorTransformImage)\n",
    "    \n",
    "    # TODO: combine these images together for the final result\n",
    "    combinedBinary = img\n",
    "    \n",
    "    return combinedBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Bird's Eye View Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birdsEyeView(img):\n",
    "    birdsEyeViewImage = img\n",
    "    \n",
    "    # TODO: use source and destination points from example writeup\n",
    "    \n",
    "    return birdsEyeViewImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Lane Lines from a Bird's Eye View Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyLaneLines(img):\n",
    "    # TODO: run function to detect\n",
    "    # TODO: run function to use previous\n",
    "    # TODO: move this functions and it's dependent functions\n",
    "    # to a separate notebook\n",
    "    binaryPerspectiveImage = img\n",
    "    \n",
    "    # TODO: getRadiusOfCurvature function\n",
    "    radiusOfCurvature = img\n",
    "    \n",
    "    return binaryPerspectiveImage, radiusOfCurvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reversing The Bird's Eye View Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birdsEyeViewToOriginal(img):\n",
    "    # TODO: add parameters (inversion matrix)\n",
    "    originalImage = img\n",
    "    return originalImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Detected Lines Overlay to Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlayDetectedLines(img, binaryDetectedLines):\n",
    "    # TODO: add weight parameter\n",
    "    overlayedImage = img\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Lane Line Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    # We must calibarate our camera with the provided chessboard images\n",
    "    # (initializes on first call, uses globals on successive calls)\n",
    "    camCalMatrix, camCalDistortionCoeff = calibrateCamera()\n",
    "    \n",
    "    # Apply distortion correction to the image with the computed\n",
    "    # camera calibration matrix and distortion coefficients\n",
    "    distortionCorrectedImage = distortionCorrection(img, camCalMatrix, camCalDistortionCoeff)\n",
    "    \n",
    "    # Accentuate possible lane lines via color transform, gradients, and color highlighting (white and yellow)\n",
    "    binaryImage = accentuateLaneLines(distortionCorrectedImage)\n",
    "    \n",
    "    # Apply a perspective transform (birds-eye view) to the binary image\n",
    "    binaryBirdsEyeViewImage = birdsEyeView(binaryImage)\n",
    "    \n",
    "    # Identify left and right lane lines on the perspective transformed binary image\n",
    "    binaryLinesBirdsEyeViewImage, radiusOfCurvature = identifyLaneLines(binaryBirdsEyeViewImage)\n",
    "    \n",
    "    # TODO: positionFromLaneCenter\n",
    "    \n",
    "    # Transform the birds eye view image back to the original perspective\n",
    "    binaryLinesImage = birdsEyeViewToOriginal(binaryLinesBirdsEyeViewImage)\n",
    "    \n",
    "    # Overlay the original image with the detected lane lines binary image\n",
    "    detectedLinesOverlayImage = overlayDetectedLines(img, binaryLinesImage)\n",
    "    \n",
    "    return detectedLinesOverlayImage\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Pipeline To a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def pipelineVideo(inputPath, outputPath, subclip=False): \n",
    "    videoClip = None\n",
    "    \n",
    "    # apply subclip if subclip flag is set\n",
    "    if subclip:\n",
    "        videoClip = VideoFileClip(inputPath).subclip(0,5)\n",
    "    else:\n",
    "        videoClip = VideoFileClip(inputPath)\n",
    "    \n",
    "    # apply pipeline to video\n",
    "    processedClip = videoClip.fl_image(pipeline)\n",
    "    \n",
    "    # write clip to the specified output path\n",
    "    %time processedClip.write_videofile(outputPath, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining and Displaying Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelineAndDisplayVideo(inputPath, outputPath, subclip=False):\n",
    "    pipelineVideo(inputPath, outputPath, subclip)\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <video width=\"100%\" height=\"100%\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(outputPath)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline on Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video_output.mp4\n",
      "[MoviePy] Writing video output_videos/project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 125/126 [00:23<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/project_video_output.mp4 \n",
      "\n",
      "Wall time: 31.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <video width=\"100%\" height=\"100%\" controls>\n",
       "      <source src=\"output_videos/project_video_output.mp4\">\n",
       "    </video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipelineAndDisplayVideo(\"project_video.mp4\", \"output_videos/project_video_output.mp4\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline on Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/challenge_video_output.mp4\n",
      "[MoviePy] Writing video output_videos/challenge_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:41<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/challenge_video_output.mp4 \n",
      "\n",
      "Wall time: 53.3 s\n"
     ]
    }
   ],
   "source": [
    "pipelineVideo(\"challenge_video.mp4\", \"output_videos/challenge_video_output.mp4\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline on Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineVideo(\"harder_challenge_video.mp4\", \"output_videos/harder_challenge_video_output.mp4\", True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
